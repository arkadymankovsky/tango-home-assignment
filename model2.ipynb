{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dataset_file = 'dataset_purchases.csv'\n",
    "    df = pd.read_csv(dataset_file)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['usd'] = df['usd'].round(2)\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['week'] = df['timestamp'].dt.isocalendar().week\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "   # Create item_id from price-coins combination\n",
    "   df['item_id'] = df['usd'].astype(str) + '_' + df['coins'].astype(str)\n",
    "   \n",
    "   # Create user-hour combinations\n",
    "   df['user_hour'] = df['user_id'].astype(str) + '_' + df['hour'].astype(str)\n",
    "   \n",
    "   # Create dataset\n",
    "   dataset = Dataset()\n",
    "   dataset.fit(\n",
    "       users=df['user_hour'].unique(),\n",
    "       items=df['item_id'].unique()\n",
    "   )\n",
    "   \n",
    "   # Build interactions\n",
    "   (interactions, weights) = dataset.build_interactions(\n",
    "       ((row['user_hour'], row['item_id'], 1.0) \n",
    "        for _, row in df.iterrows())\n",
    "   )\n",
    "   return dataset, interactions\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_stratified(df, test_size=0.2):\n",
    "   # Split users first\n",
    "   users = df['user_id'].unique()\n",
    "   train_users, test_users = train_test_split(users, test_size=test_size, random_state=42)\n",
    "   \n",
    "   train_df = df[df['user_id'].isin(train_users)]\n",
    "   test_df = df[df['user_id'].isin(test_users)]\n",
    "   \n",
    "   return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_interactions):\n",
    "   model = LightFM(learning_rate=0.05, \n",
    "                   loss='warp',\n",
    "                   no_components=30, \n",
    "                   random_state=42)\n",
    "   \n",
    "   model.fit(train_interactions, epochs=30, verbose=True)\n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, dataset, user_hour, n_items=6):\n",
    "   # Map user_hour to internal id\n",
    "   user_id_map = dataset.mapping()[0]\n",
    "   try:\n",
    "       user_idx = user_id_map[user_hour]\n",
    "   except KeyError:\n",
    "       return []  # New user-hour combination\n",
    "       \n",
    "   n_items = len(dataset.mapping()[2])\n",
    "   scores = model.predict(user_idx, np.arange(n_items))\n",
    "   \n",
    "   # Get top items\n",
    "   top_items = np.argsort(-scores)[:n_items]\n",
    "   \n",
    "   # Map back to original item_ids\n",
    "   reverse_mapping = {v: k for k, v in dataset.mapping()[2].items()}\n",
    "   return [reverse_mapping[i] for i in top_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "train_df, test_df = train_test_stratified(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, train_interactions = prepare_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = train_model(train_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendations for a user at specific hour\n",
    "user_id = \"12345\"\n",
    "hour = 14\n",
    "user_hour = f\"{user_id}_{hour}\"\n",
    "recommendations = get_recommendations(model, dataset, user_hour)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tango_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
